{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when cleaning up, import data as modules "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../acled_data/acleddata_jan_aug.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting fatalities to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fatalities\"] = pd.to_numeric(df[\"fatalities\"], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"latitude\"] = pd.to_numeric(df[\"latitude\"], errors='coerce')\n",
    "df[\"longitude\"] = pd.to_numeric(df[\"longitude\"], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wounded feature with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the number of wounded from the notes column and adding a new column 'wounded'\n",
    "import spacy\n",
    "from word2number import w2n\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def extract_wounded(text):\n",
    "    doc = nlp(text)\n",
    "    wounded_count = 0\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text.lower() == 'wounded':\n",
    "            for child in token.children:\n",
    "                if child.pos_ == 'NUM':\n",
    "                    try:\n",
    "                        wounded_count += int(child.text)\n",
    "                    except ValueError:\n",
    "                        wounded_count += w2n.word_to_num(child.text)\n",
    "            if wounded_count == 0:\n",
    "                for ancestor in token.ancestors:\n",
    "                    if ancestor.pos_ == 'NUM':\n",
    "                        try:\n",
    "                            wounded_count += int(ancestor.text)\n",
    "                        except ValueError:\n",
    "                            wounded_count += w2n.word_to_num(ancestor.text)\n",
    "                        break\n",
    "\n",
    "    return wounded_count\n",
    "\n",
    "df['wounded'] = df['notes'].apply(extract_wounded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1a: Parse event_date into a datetime format and extract month and year\n",
    "df[\"event_date\"] = pd.to_datetime(df[\"event_date\"])\n",
    "df[\"month\"] = df[\"event_date\"].dt.month\n",
    "df[\"year\"] = df[\"event_date\"].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining fatalities + wounded into casualties\n",
    "df['casualties'] = df['fatalities']+df['wounded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_columns = [\"admin1\", \"admin2\", \"admin3\", \"location\", \"latitude\", \"longitude\", \"event_date\", \"year\", \"month\", \"event_type\", \"civilian_targeting\"]\n",
    "\n",
    "# Aggregate data by location, date, and event_type\n",
    "df_agg = df.groupby(grouped_columns).agg(\n",
    "    num_events=pd.NamedAgg(column='event_type', aggfunc='size'),\n",
    "    total_casualties=pd.NamedAgg(column='casualties', aggfunc='sum')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Battlefront Proximity Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert latitude and longitude to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    # Earth radius in kilometers\n",
    "    earth_radius = 6371\n",
    "\n",
    "    # Calculate the distance\n",
    "    distance = earth_radius * c\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define coordinates of the the battlefront towns\n",
    "bakhmut_coords = (48.5956, 37.9999)\n",
    "soledar_coords = (48.6833, 38.0667)\n",
    "avdiivka_coords = (48.1394, 37.7497)\n",
    "vuhledar_coords = (48.7798, 37.2490)\n",
    "robotyne_coords = (47.44992394238662, 35.83787190517212)\n",
    "kupiansk_coords = (49.7160738622855, 37.596104878691285)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the haversine function to the dataset to calculate \n",
    "#the distances to each town and find the minimum distance:\n",
    "df_agg['distance_to_bakhmut'] = haversine(df_agg['latitude'], df_agg['longitude'], bakhmut_coords[0], bakhmut_coords[1])\n",
    "df_agg['distance_to_soledar'] = haversine(df_agg['latitude'], df_agg['longitude'], soledar_coords[0], soledar_coords[1])\n",
    "df_agg['distance_to_avdiivka'] = haversine(df_agg['latitude'], df_agg['longitude'], avdiivka_coords[0], avdiivka_coords[1])\n",
    "df_agg['distance_to_vuhledar'] = haversine(df_agg['latitude'], df_agg['longitude'], vuhledar_coords[0], vuhledar_coords[1])\n",
    "df_agg['distance_to_robotyne'] = haversine(df_agg['latitude'], df_agg['longitude'], robotyne_coords[0], robotyne_coords[1])\n",
    "df_agg['distance_to_kupiansk'] = haversine(df_agg['latitude'], df_agg['longitude'], kupiansk_coords[0], kupiansk_coords[1])\n",
    "\n",
    "\n",
    "df_agg['min_distance_to_battlefront'] = df_agg[['distance_to_bakhmut', 'distance_to_soledar', 'distance_to_avdiivka', 'distance_to_vuhledar', 'distance_to_robotyne', 'distance_to_kupiansk']].min(axis=1)\n",
    "\n",
    "# Drop the temporary distance columns\n",
    "df_agg = df_agg.drop(columns=['distance_to_bakhmut', 'distance_to_soledar', 'distance_to_avdiivka', 'distance_to_vuhledar', 'distance_to_robotyne', 'distance_to_kupiansk'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode civilian_targeting as a binary column\n",
    "df_agg['civilian_targeting_encoded'] = df_agg['civilian_targeting'].apply(lambda x: 1 if x == 'Civilian targeting' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode event_type and incorporate civilian_targeting_encoded for 'Explosions/Remote violence'\n",
    "df_agg['event_battles'] = (df_agg['event_type'] == 'Battles').astype(int)\n",
    "df_agg['event_explosions'] = ((df_agg['event_type'] == 'Explosions/Remote violence') & (df_agg['civilian_targeting_encoded'] == 0)).astype(int)\n",
    "df_agg['event_explosions_civilians'] = ((df_agg['event_type'] == 'Explosions/Remote violence') & (df_agg['civilian_targeting_encoded'] == 1)).astype(int)\n",
    "df_agg['event_violence_civilians'] = (df_agg['event_type'] == 'Violence against civilians').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-SNE Variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Selecting the columns we want to input into t-SNE\n",
    "features = ['num_events', 'total_casualties', 'event_battles', 'event_explosions', 'event_explosions_civilians', 'event_violence_civilians']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(df_agg[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-D Embeddings from t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(scaled_features)\n",
    "df_agg['tsne_0'] = tsne_results[:, 0]\n",
    "df_agg['tsne_1'] = tsne_results[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# KDE on t-SNE results\n",
    "kde = gaussian_kde(np.vstack([df_agg['tsne_0'], df_agg['tsne_1']]))\n",
    "density = kde(np.vstack([df_agg['tsne_0'], df_agg['tsne_1']]))\n",
    "\n",
    "# Identify the densest point\n",
    "densest_idx = np.argmax(density)\n",
    "densest_point = (df_agg.iloc[densest_idx]['tsne_0'], df_agg.iloc[densest_idx]['tsne_1'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Densest Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['distance_to_densest'] = np.sqrt((df_agg['tsne_0'] - densest_point[0])**2 + (df_agg['tsne_1'] - densest_point[1])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Distances into Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_factor = 0.05  # This is just an example value; adjust as needed\n",
    "df_agg['tsne_distance_points'] = 50 * np.exp(-decay_factor * df_agg['distance_to_densest'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proximity based Score on 'min_distance_to_battlefront'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['distance_points'] = 100 * np.exp(-decay_factor * df_agg['min_distance_to_battlefront'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hazard Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tsne_distance_points with distance_points using the weights you provided to obtain the final hazard_score.\n",
    "weight_distance = 0.7  # This is the weight for the distance to the battlefront\n",
    "weight_tsne = 0.3     # This is the weight for the t-SNE derived score\n",
    "\n",
    "df_agg['hazard_score'] = (df_agg['distance_points'] * weight_distance) + (df_agg['tsne_distance_points'] * weight_tsne)\n",
    "\n",
    "# Normalize the hazard_score\n",
    "min_hazard = df_agg['hazard_score'].min()\n",
    "max_hazard = df_agg['hazard_score'].max()\n",
    "\n",
    "# Apply Min-Max scaling to adjust scores between 0 and 100\n",
    "df_agg['hazard_score'] = ((df_agg['hazard_score'] - min_hazard) / (max_hazard - min_hazard)) * 100\n",
    "df_agg['hazard_score'] = df_agg['hazard_score'].round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.loc[df_agg['min_distance_to_battlefront'] <= 30, 'hazard_score'] = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.loc[df_agg['hazard_score'] < 30, 'hazard_score'] = 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.loc[df_agg['event_type'] == 'Battles', 'hazard_score'] = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hazard Level diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logic:\n",
    "\n",
    "- Identify high hazard locations\n",
    "- Function to check whether there's a row with a matching admin1 column. If a match is found compute the distance between the coordinates, record the distance between them. Iterate through all locations within that admin1 border and whenever we have a shorter distance we replace the old one. Also, record the hazard score of the location which has the shortest distance to our location. \n",
    "- If our row's admin1 isn't matching with any of the locations we skip the element and move to the next.\n",
    "- This location will be incremented by a decayed amount of hazard level from the hot zone, depending on how far away it is. Percentage inheritance up to testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Importing the Haversine package - I want to try this version instead of the one implemented earlier\n",
    "from haversine import haversine\n",
    "\n",
    "# Step 1: Extract high hazard locations\n",
    "high_hazard_locs = df_agg[df_agg['hazard_score'] >= 80][['admin1','latitude', 'longitude', 'hazard_score']]\n",
    "\n",
    "high_hazard_locs = high_hazard_locs.drop_duplicates(subset=['latitude', 'longitude'], keep=False)\n",
    "\n",
    "# Step 2: Identify locations within 50km radius using row-wise function\n",
    "def compute_distance(row, locations):\n",
    "    if row['admin1'] in locations['admin1'].values:\n",
    "        # find the index of the first occurrence\n",
    "        idx = locations[locations['admin1']==row['admin1']].index[0]\n",
    "        # vars for distance and score\n",
    "        distance = 81 # this is a baseline value to flag the one's that are outside of radius\n",
    "        hazard = 0 \n",
    "        for i, r in locations.loc[idx:].iterrows():\n",
    "            if r['admin1'] == row['admin1']:\n",
    "                # compute distance between two locations \n",
    "                # check if its within 50km \n",
    "                delta = haversine((row['latitude'],row['longitude']), (r['latitude'],r['longitude']), unit='km')\n",
    "                if delta <= distance:\n",
    "                    distance = delta\n",
    "                    hazard = r['hazard_score']\n",
    "            else:\n",
    "                break\n",
    "        # apply exponential decay to distance\n",
    "        hazard_decayed = 0.8*hazard * (1-0.02)**(distance)\n",
    "        return row['hazard_score']+hazard_decayed\n",
    "        \n",
    "        \n",
    "    return row['hazard_score']\n",
    "\n",
    "\n",
    "df_agg['hazard_score'] = df_agg.apply(lambda x: compute_distance(x, high_hazard_locs) if x['hazard_score']<80 else x['hazard_score'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['hazard_score'] = df_agg['hazard_score'].clip(0,100)\n",
    "df_agg['hazard_score'] = df_agg['hazard_score'].round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting data to handle inconsistencies with naming and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.loc[df_agg['admin2']=='Kyiv', 'admin3'] = 'Kyiv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.loc[df_agg['location']=='Kherson', 'admin2'] = 'Khersonskyi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_agg[~df_agg['admin3'].str.strip().eq('')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.to_csv('Hazards_latest.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
